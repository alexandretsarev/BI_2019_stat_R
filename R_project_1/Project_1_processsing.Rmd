---
title: "Работа про проекту"
author: "anonymus"
date: "Ноябрь 3, 2019"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
---

# Задание 1
**Описание**: нам надо как-то объединить наблюдения в единую таблицу. Пожалуйста, напиши 
пользовательскую функцию, благодаря которой мы сможем собрать все наши наблюдения
воедино. Так как экспедиции являются ежегодными, а данные всегда называются
по разному, то функция должна объединять все файлы одного расширения из заданной 
папки. Суммарно у тебя должно получиться 4177 наблюдений

**Решение**: я вообразил что у меня на компьютере не хватит памяти для данных всех моллюсков - отказался разархивировать
файл Data.zip и решил прочитать сразу из него. Вот что вышло.

```{r, echo=TRUE,message=FALSE}
library(data.table)
library(dplyr)

read_allCsvZip <- function(path_to_zip){
  fread(paste("unzip -p", path_to_zip, sep = " "), header = T) %>% 
    filter(.[,1] != colnames(.)[1]) -> data
} 

test <- read_allCsvZip("Data.zip")
```

Посмотрим сколько получилось наблюдений и колонок, видим что все хорошо.
```{r, echo=TRUE,message=FALSE}
test %>% summarise(n_rows = nrow(.), n_columns =  ncol(.))
```

Но реальность говорит о том, что у нас всего 11 файлов, поэтому я написал что-то неоптимальное, написав функцию, 
которая добавила колонку с фамилией ученого, который ~~виноват~~ собрал данные, чтобы если что потом ~~обвинить~~ наградить его за 
хорошее заполнение таблиц, в ходе сбора и обработки материала. Однако для этой функции, требуется разархивировать файл.


```{r, echo=TRUE}
read_allCsvZip_person <- function(path_to_zip){
  unzip(path_to_zip)
  path <- gsub(path_to_zip, pattern = "\\.zip",replacement = "")
  whole_data <- data.frame()
  researcher <- vector()
  my_files <- list.files(path, pattern=".csv", full.names=TRUE,recursive=FALSE)

  for (file in (1:length(my_files))){
    researcher <- append(researcher,
                         rep(x = gsub(basename(my_files[file]),pattern = "\\.csv",replacement = ""),nrow(read.csv(my_files[file]))))
    whole_data <- rbind(whole_data, read.csv(my_files[file]))
  }
  
  whole_data$researcher <- as.factor(researcher)
  
  return(whole_data)
}

data <- read_allCsvZip_person("Data.zip")
```

Посмотрим на данные, только на некоторые колонки (чтобы удостовериться, что ученые добавлены)
```{r, echo=TRUE,message=FALSE}
data %>% group_by(researcher) %>% slice(1) %>% select(1,3,4,5,10)
```

```{r, include=F}
rm(test) # удаляю тот тестовый файл, который результировала первая функция: дальше буду работать датафреймом, где есть фамилии ученых
```

# Задание 2
**Описание**: посмотри, действительно ли все данные корректны? Если найдешь, что что-то не так, то исправь это, пожалуйста. Только объясни нам, почему ты воспользовался именно этим подходом. Может быть у него есть альтернативы?

**Решение**:
Сначала нужно взглянуть на данные, посмотреть что они из себя представляют.
```{r, echo=T}
str(data)
```
Видим, что есть два типа данных. Первое, на что обращаю внимание это, что количество колец (Rings) не является числовой или факторной переменнной; пол (Sex) закодирован цифрами 1, 2, 3, но тип переменных является строкой, так может быть, но лучше посмотреть более пристально, тем более что это легко - всего три типа пола. Длина (Length) - очевидно должна быть числовой, а в данных она строковая, тоже посмотрим по-ближе. Остальные значения не вызывают сомнений на первый взгляд, так как это различные замеры моллюсков, которые являются числовыми. Хотя там могут отсутствующие значения _NA_, но с этим мы будем справляться позже. Ученый, который собрал данные закодирован как фактор, как это и планировалось в пользовательской функции. 

Сразу для удобства переименуем колонку с полом в _нормальное название_ - Sex.

```{r,echo=T}
colnames(data)[2] <- "Sex"

levels(as.factor(data$Sex))
```
Видим проблему, есть значения которые указаны ошибочно (не 1,2,3 кодировкой).

Глядя на данные мы видим, что кто-то любит писать полное название название пола (male) или писать цифры строчно (three), когда подавляющее большинство следует правилу 1,2 и 3. Мы хотим сделать наш отчет универсальным, и попробуем учесть все эти ошибки вне зависимсоти от регистра, а также вдруг этот _кто-то_ добавит какие-то дополнительные случайные символы (malee, female1 и все в таком духе). Забавно также, что слово uvenile у меня также вызвало трудности, правильно пишется juvenile. Таким образом, просто попытаемся учесть все возможные ошибки, чтобы расширить работу этой функции на новые датасеты, с какими-то, возможно, новыми ошибками.


```{r, echo=T}

sex_fix <- function(y){
  if(grepl(x = y,pattern = "female")){
    y <- 1
  } else if (grepl(x = y,pattern = "male")){
    y <- 2
  } else if (grepl(x = y, pattern = "uvenile")){
    y <- 3
  } else if (grepl(x = y, pattern = "one")){
    y <- 1
  } else if (grepl(x = y, pattern = "two")){
    y <- 2
  } else if (grepl(x = y, pattern = "ree")){
    # ree указано специально, так как есть люди которые пишут three как tree
    y <- 3
  }
  return(y)
}

levels(as.factor(data$Sex))
data$Sex <- sapply(tolower(data$Sex),sex_fix)
```
Также для удобства переименуем этот код в факторную переменную с полным названием пола, чтобы не задаваться вопросом каждый раз глядя на данные. 
```{r, echo=T}
data$Sex <- sapply(data$Sex, gsub, pattern = "1", replacement = "male")
data$Sex <- sapply(data$Sex, gsub, pattern = "2", replacement = "female")
data$Sex <- sapply(data$Sex, gsub, pattern = "3", replacement = "juvenile")
data$Sex <- as.factor(data$Sex)
```

Теперь разбираемся с переменной длины (Lenght). Эта колонка должна быть числовым вектором, а не строковым. Возьем и преобразуем эту колонку в числовой тип, все что не число будет преобразовано в _NA_. Создадим вектор vec - вектор из тех самых нечисловых значений, которые вызывают у нас подозрения и посмотрим на него.

```{r, echo=T}
vec <- which(is.na(as.numeric(as.vector(data$Length)))) 
data$Length[as.vector(vec)]
```
Видим, что есть отсутсвующие значения, мы с ними справимся позже. Есть значение, где ученый забыл добавить данные, но после трансформации наших данных в числовые, оно станет _NA_. Мы сделали это все, для того, чтобы посмотреть, что же такое в этой колонке записано неверно.   

```{r, echo=T}
data$Length <- sapply(data$Length, as.numeric)
rm(vec) # удаление вектора, больше он нам не нужен
```

Теперь разбираемся с переменной Rings. Применим такой же трюк с преобразованием ее в числовой тип и поймаем значения, которые стали _NA_  
```{r, echo=T}
vec <- which(is.na(as.numeric(as.vector(data$Rings))))
data$Rings[vec] 
```
тут только одно значение подводит, а именно, nine, которое должно быть 9. В принципе его легко исправить:

data$Rings[vec] <- 9 или же 

data\$Rings <- sapply(data\$Rings, gsub, pattern="nine", replacement = 9)

Есть и другие способы исправить эту ошибку, но есть проблема. В критериях к оценке ответа есть также применимость для других датасетов. Если же исправлять эту ошибку сейчас любым из способов: те которые я предложил, или же создать датафрейм по типу 
nine - 9, eight - 8 и так далее. Но так или иначе этот подход не будет универсальным. Цифр (или других значений) может быть много, они могут быть написаны с ошибкой или вообще по-другому acht, seben и так далее. Невозможно учесть все. 

Сейчас я борюсь за это значение, поэтому исправлю это значение таким образом:

```{r, echo=T}
data$Rings <- sapply(data$Rings,gsub,pattern="nine",replacement=9)
data$Rings <- as.numeric(data$Rings)
```

Но будущие ошибки, которые записаны как-то так мы не учтем. 


Теперь нужно разобраться с _NA_ значениями, с теми которые были и с тем которые мы _"сделали"_ в предыдущих шагах.
```{r, echo=T}
colSums(is.na(data))
```
Работать с _NA_ можно двумя путями: фильтровать или импутировать каким-нибудь образом. Но значения могут быть факторными, их импутировать нельзя, либо нужно строить регрессионную модель и предсказывать по другим значениям этот фактор (например пол). В нашем случае есть одно пропущенное значение в колонке Sex. Мы его отфильтруем. Есть другие значения которые пропущены в числовых колонках. Данных много, можно отфильтровать, но и импутировать, например среднее. Это мы и сделаем. Оставишиеся значения мы выкинем. 

```{r,echo=T}
data[,c(3:7,9)] %>% mutate_if(is.numeric, funs(ifelse(is.na(.), mean(. ,na.rm = T), .))) -> data[,c(3:7,9)]


library(tidyr)
drop_na(data) -> data

```

Посмотрим теперь сколько значений осталось в нашем датафрейме после всех фильтраций. Ожидается что выкинуто одно значение.
```{r,echo=T}
data %>% summarise(nrow = nrow(.), ncol = ncol(.))
```

**Объяснение "подхода"**, который я применял для вычищения данных. Я знаю, что это за данные и знаю, что подозревать, как, например, переменные Length, которая согласно здравому смыслу должнать быть числовой. Если же там есть, что то кроме чисел, то они заменятся на NA, что я отлавливал через which[is.na(data[,column])], далее я на это смотрел и предпринимал, что делать. Эти данные маленькие в принципе можно было сделать levels(as.factor(data[,column])) и я получил бы все градации факторов, просмотрел бы их и увидел ошибки. Но а что если у меня не 4 тысячи строк и 40 миллионов? Поэтому я и отлавливал NA, зная, что любое _нечисло_ будет превращаться в NA и их уже в ручную смотрел, так как вижу единую таблицу или вектор ошибочных значений. Не знаю, какая может быть альтернатива проверке данных на всякие странные значения, как если бы не знать, что это и смотреть частно по колонкам, которые вызывают сомнения - все ли хорошо с ними или нет. 

# Задание 3
**Описание**: рассчитай среднее значение и стандартное отклонение переменной Length для
моллюсков разного пола

**Решение**:
```{r,echo=T}
data %>% group_by(Sex) %>% summarise(mean = mean(Length), sd = sd(Length))
```

# Задание 4
**Описание**: у какого процента моллюсков значение переменной Height не превышает 0.165?

**Решение**: 
```{r,echo=T}
(data %>% filter(Height <= 0.165) %>% count())/nrow(data)*100 -> ans
paste("Answer: ",round(ans,2), "%", sep = " ")
```
```{r,include=F}
rm(ans)
```

# Задание 5
**Описание**: чему равняется значение переменной Length, которое выше чем у 92% от всех наблюдений?

**Решение**:
```{r, echo=T}
data %>% arrange(-Length) %>% slice(round(nrow(data)*0.92,2)) %>% select(Length) -> ans
paste("Answer is",ans,sep = " ")
```
```{r,include=F}
rm(ans)
```

# Задание 6
**Описание**: Создай новую переменную Lenght_z_scores и сохрани в нее значения переменной
Length после её стандартизации.

**Решение**:
```{r, echo=T}
data$Length_z_scores <- scale(data$Length)
tbl_df(data[,c(3,11)])

library(ggplot2)
library(RColorBrewer)

ggplot(data,aes(Length_z_scores))+
  geom_density(fill=brewer.pal(n = 3,"Set1")[1],alpha=0.3)+
  xlab("Standardized Length value")+ylab("Density")+
  labs(title = "Standardized Length value distirbution")+
  theme_bw()
```

# Задание 7
**Описание**: Сравни между собой диаметр моллюсков с числом колец 5 и 15. К каким выводам
ты пришел? Пожалуйста, оформи результаты так, чтобы мы сразу могли использовать
их для статьи.

**Решение**:
Посмотрим на распределения диаметров раковин моллюск по группам и проверим на нормальность (Rings = 15 и 5).
```{r, echo=T}
library(car)
qqPlot((subset(data,Rings==15))$Diameter,distribution = "norm",
       xlab = "expected quantiles",
       ylab = "obtained quantiles",
       main = "QQ-plot of diameter values, Rings = 15")
qqPlot((subset(data,Rings==5))$Diameter,distribution = "norm",
       xlab = "expected quantiles",
       ylab = "obtained quantiles",
       main = "QQ-plot of diameter values, Rings = 5")
```

```{r,echo=T}
data %>% filter(Rings == 5 | Rings == 15) %>% 
  ggplot(.,aes(x=Diameter,fill=as.factor(Rings)))+
  geom_density(alpha=0.3)+
  xlab("Shell diameter")+
  scale_fill_brewer(palette = "Set1")+
  labs(title = "The distribution of shell diameters of shellfishes with 5 and 15 rings",fill="Rings")+
  theme_bw()
```
Видим, что распределения в двух группам близки к нормальному, и распределение диаметров раковин моллюсков
с 15 кольцами смещено правее моллюсков с 5 кольцами. Важно отметить, нас достаточно большие выборки. Таким образом мы можем применить t-test, для проверки достоверности отличий между выборками по параметру _Diameter_.

Можем составить нулевую и альтернативные гипотезы:
Нулевая - раковины моллюсков с количеством колец 5 и 15 не различаются

Альтернативная - раковины моллюсков (по параметру Diameter) с количеством колец 5 меньше чем у моллюсков с диаметром 15. 

```{r, echo=T}
t.test_res <- t.test(Diameter ~ Rings, subset(data,Rings==c(5,15)),alternative="less")
t.test_res

library(ggpubr)

ggplot(subset(data,Rings==c(5,15)), aes(y=Diameter,x=as.factor(Rings),fill=as.factor(Rings)))+
  geom_boxplot(alpha=0.4)+
  geom_jitter(alpha=0.3)+
  scale_fill_brewer(palette = "Set1")+
  xlab("Rings")+
  labs(title="Boxplot of diameter values of mollusks with 5 and 15 rings",fill="Rings")+
  theme_bw()+
  stat_compare_means(method = "t.test",paired = F,label = "p.signif",ref.group = 1)
```
**Вывод**: отвергаем нулевую гипотезу: диаметры раковин моллюсков с 5 кольцами достоверно меньше чем диаметры раковин моллюсков с 15 кольцами $\sf{t_{99.175}=-23.973, p=2.2\cdot10^{-16}}$. Ууказали число степеней свобод (99.175), значение t-критерия (-23.973) а также само значение p-value. 

# Задание 8
**Описание**: нас особенно интересуют переменные Diameter и Whole_weight. Что ты можешь про
них сказать? Есть ли у нас основания предполагать, что они могут быть
взаимосвязаны? Как ты это определил?

**Решение**: необходимо сделать корреляционный анализ, для этого важно понимать, какое распределение у исследуемых переменных. Построим QQ-plot и density plot для каждой их них.
```{r,echo=T}
qqPlot(data$Whole_weight,distribution = "norm",
       xlab = "expected quantiles",
       ylab = "obtained quantiles",
       main = "QQ-plot of whole_weight values")

qqPlot(data$Diameter,distribution = "norm",
       xlab = "expected quantiles",
       ylab = "obtained quantiles",
       main = "QQ-plot of Diameter values")

ggplot(data)+
  geom_density(aes(Diameter),fill=brewer.pal(n = 3,"Set1")[1],alpha=0.3)+
  theme_bw()+
  ylab("Density")+
  labs(title = "Distribution of mollusk shells diameters")

ggplot(data)+
  geom_density(aes(Whole_weight),fill=brewer.pal(n = 3,"Set1")[2],alpha=0.3)+
  theme_bw()+
  ylab("Density")+
  labs(title = "Distribution of mollusk shells Whole_wight value")

```

Видим, что в обоих случаях распределение далеко от нормального, поэтому используем критерий корреляции Спирмена.
$$\rho = 1- {\frac {6 \sum_{i=1}^{n} d_i^2}{n(n^2 - 1)}}$$

```{r,echo=T,warning=F}
cor_result <- cor.test(data$Diameter, data$Whole_weight, method ="spearman")
cor_result
```
**Вывод**: мы видим, что связь между переменная крайне сильная, о чем говорит высокий коэффициент $\rho$ и низкий p value.  